{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google COLAB Settings\n",
    "In this section are certain processes that should be run when running the code through Google COLAB so to have access to a GPU. If such is the case, uncomment the sections and run them sequentially. otherwise, feel free to skip directly to [Imports](#Imports)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# from os.path import exists\n",
    "# from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "# platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "# cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "# accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "# !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "# !pip install livelossplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Drive\n",
    "This portion is exclusively for development on _my_ end. I use Google Drive to access the training/testing data without having to redownload it each time the Google COLAB runtime is reset. \n",
    "\n",
    "Of course anyone who does not have access to my Google credentials will not be able to access my Drive. As such, these users should skip directly to [Imports](#Imports). The result will be that torchvision will personally download the CIFAR data from the web each time the COLAB runtime is reset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mounting Drive\n",
    "This mounts Google Drive to the local runtime. If Drive is already mounted, then of course, it will not try to mount it again. It will of course ask for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data from Drive\n",
    "Here I import the CIFAR data which I have previously downloaded and stored in my Google Drive. To do so I copy the corresponding directory from my Google Drive into the COLAB Runtime to avoid having to redownload it each time my COLAB runtime is reset. The ```-n``` flag is set to avoid overwriting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp -r -n /content/gdrive/My\\ Drive/Education/Undergraduate/Year_3/Computer_Science/SSA/Machine_Learning/Coursework/ML_Classifier-Pegasus-Generator/data /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision  # provides specific datasets\n",
    "import matplotlib.pyplot as plt  # provides plotting capabilities\n",
    "from livelossplot import PlotLosses  # provides live plotting capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the device for the user.\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Device being used:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(iterable):\n",
    "    \"\"\"Helper function to make getting another batch of data easier\"\"\"\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "            \n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    \"\"\"Plots predicted images\"\"\"\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    color = '#335599' if predicted_label == true_label else '#ee4433'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                  100*np.max(predictions_array),\n",
    "                                  class_names[true_label]),\n",
    "                                  color=color)\n",
    "\n",
    "    \n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    \"\"\"Plots the value arrays associated with particular predictions\"\"\"\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(len(class_names)), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('#ee4433')\n",
    "    thisplot[true_label].set_color('#335599')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "    '''A simple classifier'''\n",
    "    \n",
    "    # define initialization\n",
    "    def __init__(self):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        # initialize network layers\n",
    "        layers = nn.ModuleList()\n",
    "        # 3 (colors) by 32 (width) by 32 (height) tensor \n",
    "        layers.append(nn.Linear(in_features=3 * 32 * 32, out_features=512))\n",
    "        # rectifier layer\n",
    "        layers.append(nn.ReLU())\n",
    "        # 100 class outputs\n",
    "        layers.append(nn.Linear(in_features=512, out_features=100))\n",
    "        self.layers = layers\n",
    "\n",
    "    # define network structure\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)  # flatten input as we're using linear layers\n",
    "        for m in self.layers:\n",
    "            x = m(x)\n",
    "        return x\n",
    "\n",
    "class EarlyStop:\n",
    "    \"\"\"Object that checks for early stopping. A class is used to maintain a state\"\"\"\n",
    "    \n",
    "    def __init__(self, patience):\n",
    "        \"\"\"initializes instance variables\"\"\"\n",
    "        self.patience = patience\n",
    "        self.annoyance = 0\n",
    "        self.stop = False\n",
    "        self.min_loss = np.Inf\n",
    "        self.epoch = 0\n",
    "        \n",
    "    def __call__(self, model, epoch, curr_loss):\n",
    "        \"\"\" When the Model is called on a current loss measure for a given model,\n",
    "            check whether the current loss is greater than at the last checkpoint, \n",
    "            if so increase the annoyance until patience runs out at which point we \n",
    "            flag this. Record checkpoints as loss improves.\n",
    "        \"\"\"\n",
    "        # if the minimum loss has yet to be measured (base case)\n",
    "        if self.min_loss == np.Inf:\n",
    "            # set it to the one currently being checked for\n",
    "            self.min_loss = curr_loss\n",
    "            \n",
    "        # if the miniumum loss is smaller than the current loss\n",
    "        elif self.min_loss < curr_loss:\n",
    "            # increase the level\n",
    "            self.annoyance += 1\n",
    "            print(f'Current loss is greater than previously measured')\n",
    "            print(f'Increasing annoyance to {self.annoyance} out of {self.patience}')\n",
    "            # once patience threshold is met\n",
    "            if self.annoyance >= patience:\n",
    "                print(f'Patience limit has been reached -- Early stopping')\n",
    "                # set a flag that enough is enough\n",
    "                self.stop = True\n",
    "        # if the minimum loss is greater than the current loss  \n",
    "        else:\n",
    "            print(f'Current loss is smaller than previously measured')\n",
    "            # reset the minimum loss to the current loss\n",
    "            self.min_loss = curr_loss\n",
    "            # record a checkpoint\n",
    "            self.checkpoint(model, epoch)\n",
    "            # reset the annoyance level to zero\n",
    "            print(f'Resetting annoyance to 0')\n",
    "            self.annoyance = 0\n",
    "    \n",
    "    def checkpoint(self, model, epoch):\n",
    "        \"\"\"Saves the model for it to be loaded later on. Takes note of the checkpoint epoch\"\"\"\n",
    "        print(f'Setting checkpoint')\n",
    "        torch.save(model.state_dict(), 'Training/Checkpoints/checkpoint.pt')\n",
    "        self.epoch = epoch\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list containing class names\n",
    "class_names = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'computer_keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle',\n",
    "               'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train transform (can add augmentation)\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# define test transfrom (no augmentation should be added)\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Datasets\n",
    "The training and validation datasets will both originate from the CIFAR training set. This is because later on they will be split according to some ratio such that for example training is 4/5 of the training set and validation is 1/5 of the training set. This is to perform regularization (such as early stopping) in an isolated manner from the testing dataset, which is in fact loaded from the test set.\n",
    "\n",
    "The careful reader will notice that despite being loaded from the same set, training and validation datasets still differ as each will have their own transforms, allowing the former for example to be augmented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training dataset from training\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='data', train = True, download = True, transform = train_transform)\n",
    "\n",
    "# get the testing dataset from testing\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='data', train = False, download = True, transform = test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Datasets for usage\n",
    "We've downloaded the data. Now we have to load it for our model to use it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "\n",
    "# instantiate trainingdata loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "\n",
    "# instantiate test data loader with no shuffling\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "# create iterators for later use\n",
    "train_iterator = iter(cycle(train_loader))\n",
    "test_iterator = iter(cycle(test_loader))\n",
    "\n",
    "print(f'> Size of training dataset {len(train_loader.dataset)}')\n",
    "print(f'> Size of test dataset {len(test_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Some of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pyplot figure\n",
    "plt.figure(figsize=(10, 10))\n",
    "# make a 5 by 5 grid of images from test dataset\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    # get rid of tickmarks\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    # get rid of grid\n",
    "    plt.grid(False)\n",
    "    # show the image\n",
    "    plt.imshow(test_loader.dataset[i][0].permute(\n",
    "        0, 2, 1).contiguous().permute(2, 1, 0), cmap=plt.cm.binary)\n",
    "    # label\n",
    "    plt.xlabel(class_names[test_loader.dataset[i][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training/Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model object\n",
    "N = MyNetwork().to(device)\n",
    "\n",
    "print(f'> Number of network parameters {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
    "\n",
    "# initialise the optimiser (stochastic gradient descent)\n",
    "optimiser = torch.optim.SGD(N.parameters(), lr=0.001)\n",
    "# set start epoch\n",
    "epoch = 0\n",
    "# initialize live loss plot object\n",
    "liveplot = PlotLosses()\n",
    "\n",
    "\n",
    "\n",
    "# if we want to visualize rather than record\n",
    "VIS_BOOL = True\n",
    "\n",
    "# if we are recording the results instead:\n",
    "if not VIS_BOOL:\n",
    "    # initialize train record lists\n",
    "    train_acc = []\n",
    "    train_loss = []\n",
    "    # initialize test record lists\n",
    "    test_acc = []\n",
    "    test_loss = []\n",
    "    \n",
    "# initialize early stopping object\n",
    "early_stopper = EarlyStop(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training process\n",
    "while (epoch < 100): # training for 100 epochs\n",
    "    # arrays for epoch metrics\n",
    "    train_loss_arr = np.zeros(0)\n",
    "    train_acc_arr = np.zeros(0)\n",
    "    # same for testing\n",
    "    test_loss_arr = np.zeros(0)\n",
    "    test_acc_arr = np.zeros(0)\n",
    "\n",
    "    # set the model to training mode\n",
    "    N.train()\n",
    "    # iterate over the training dateset\n",
    "    for (x, t) in train_loader:\n",
    "        # set the data and target tensors to the GPU\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        # initialize the gradient to zero\n",
    "        optimiser.zero_grad()\n",
    "        # calculate prediction by running input through Neural Network\n",
    "        p = N(x)\n",
    "        pred = p.argmax(dim=1, keepdim=True)\n",
    "        # calculate loss between prediction and target\n",
    "        loss = torch.nn.functional.cross_entropy(p, t)\n",
    "        # backpropagate loss\n",
    "        loss.backward()\n",
    "        # performs a parameter update (train)\n",
    "        optimiser.step()  \n",
    "        # if we want to visualize our results\n",
    "        if VIS_BOOL:\n",
    "            # record the loss for this image\n",
    "            train_loss_arr = np.append(train_loss_arr, loss.cpu().data)\n",
    "            # record the accuracy for this image\n",
    "            train_acc_arr = np.append(train_acc_arr, pred.data.eq(\n",
    "                t.view_as(pred)).float().mean().item())\n",
    "    \n",
    "    # set the model to evaluation mode\n",
    "    N.eval()\n",
    "    # iterate over the test dataset\n",
    "    for x, t in test_loader:\n",
    "        # get input and respective targets from testing dataset\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        # calculate prediction by running input through Neural Network\n",
    "        p = N(x)\n",
    "        # calculate loss\n",
    "        loss = torch.nn.functional.cross_entropy(p, t)\n",
    "        pred = p.argmax(dim=1, keepdim=True)\n",
    "\n",
    "        # record the loss for this epoch\n",
    "        test_loss_arr = np.append(test_loss_arr, loss.cpu().data)\n",
    "        # record the accuracy for this epoch\n",
    "        test_acc_arr = np.append(test_acc_arr, pred.data.eq(\n",
    "            t.view_as(pred)).float().mean().item())\n",
    "\n",
    "    # calculate the overall loss and and accuracy for this epoch\n",
    "    #training\n",
    "    epoch_train_acc = train_acc_arr.mean()\n",
    "    epoch_train_loss = train_loss_arr.mean()\n",
    "    #testing\n",
    "    epoch_test_acc = test_acc_arr.mean()\n",
    "    epoch_test_loss = test_loss_arr.mean()\n",
    "    \n",
    "    \n",
    "        \n",
    "    # if we want to visualize live\n",
    "    if VIS_BOOL:\n",
    "        # draw the training results live\n",
    "        # NOTE: live plot library has naming forcing our 'test' to be called 'validation'\n",
    "        liveplot.update({\n",
    "            'accuracy': epoch_train_acc,\n",
    "            'val_accuracy': epoch_test_acc,\n",
    "            'loss': epoch_train_loss,\n",
    "            'val_loss': epoch_test_loss\n",
    "        })\n",
    "        liveplot.draw()\n",
    "    # if we prefer to record the results for later usage\n",
    "    else:\n",
    "        # append to the record arrays\n",
    "        train_acc.append(epoch_train_acc)\n",
    "        train_loss.append(epoch_train_loss)\n",
    "        # same for test\n",
    "        test_acc.append(epoch_train_acc)\n",
    "        test_loss.append(epoch_train_loss)\n",
    "        \n",
    "        # print to keep track of progress\n",
    "        print(epoch)\n",
    "    \n",
    "    # move on to the next epoch\n",
    "    epoch += 1\n",
    "\n",
    "print (\"Training completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # load the checkpointed model\n",
    "# N.load_state_dict(torch.load('Training/Checkpoints/checkpoint.pt'))\n",
    "# epoch = early_stopper.epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = next(test_iterator)\n",
    "test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "# perform inference on the test dataset - use softmax to format this as a sum of probabilities normalized to 1\n",
    "test_preds = torch.softmax(N(test_images).view(test_images.size(0), len(class_names)), dim=1).data.squeeze().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 4\n",
    "num_cols = 4\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, test_preds, test_labels.cpu(), test_images.cpu().squeeze().permute(1,3,2,0).contiguous().permute(3,2,1,0))\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, test_preds, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Test Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we had previously decided to record the test accuracy and loss throughout\n",
    "if not VIS_BOOL:\n",
    "    # get \n",
    "    epochs_arr = list(range(1, epoch+1))\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    \n",
    "    ax1.plot(epochs_arr, test_acc)\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.set_title(\"Test Accuracy over Training Epochs\")\n",
    "    \n",
    "    ax2.plot(epochs_arr, test_loss)\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Accuracy\")\n",
    "    ax2.set_title(\"Test Loss over Training Epochs\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "else:\n",
    "    print(\"You have not previously recorded the test accuracy and loss over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Best Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not VIS_BOOL:\n",
    "    print(\"The value for the test accuracy is {} %\".format(test_acc[-1]*100))\n",
    "else:\n",
    "    print(\"You have not previously recorded the test accuracy and loss over time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
