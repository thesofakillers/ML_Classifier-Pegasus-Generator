{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google COLAB Settings\n",
    "In this section are certain processes that should be run when running the code through Google COLAB so to have access to a GPU. If such is the case, uncomment the sections and run them sequentially. otherwise, feel free to skip directly to [Imports](#Imports)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# from os.path import exists\n",
    "# from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "# platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "# cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "# accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "# !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "# !pip install livelossplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Drive\n",
    "This portion is exclusively for development on _my_ end. I use Google Drive to access the training/testing data without having to redownload it each time the Google COLAB runtime is reset. \n",
    "\n",
    "Of course anyone who does not have access to my Google credentials will not be able to access my Drive. As such, these users should skip directly to [Imports](#Imports). The result will be that torchvision will personally download the CIFAR data from the web each time the COLAB runtime is reset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mounting Drive\n",
    "This mounts Google Drive to the local runtime. If Drive is already mounted, then of course, it will not try to mount it again. It will of course ask for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data from Drive\n",
    "Here I import the CIFAR data which I have previously downloaded and stored in my Google Drive. To do so I copy the corresponding directory from my Google Drive into the COLAB Runtime to avoid having to redownload it each time my COLAB runtime is reset. The ```-n``` flag is set to avoid overwriting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp -r -n /content/gdrive/My\\ Drive/Education/Undergraduate/Year_3/Computer_Science/SSA/Machine_Learning/Coursework/ML_Classifier-Pegasus-Generator/data/ /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import time\n",
    "import math\n",
    "import pickle # for serialization\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision  # provides specific datasets\n",
    "import matplotlib.pyplot as plt  # provides plotting capabilities\n",
    "from livelossplot import PlotLosses  # provides live plotting capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sets the device for the user.\n",
    "device = torch.device(\n",
    "    'cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(\"Device being used:\", device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(iterable):\n",
    "    \"\"\"Helper function to make getting another batch of data easier\"\"\"\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x\n",
    "\n",
    "            \n",
    "def plot_image(i, predictions_array, true_label, img):\n",
    "    \"\"\"Plots predicted images\"\"\"\n",
    "    predictions_array, true_label, img = predictions_array[i], true_label[i], img[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    plt.imshow(img, cmap=plt.cm.binary)\n",
    "\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "    color = '#335599' if predicted_label == true_label else '#ee4433'\n",
    "\n",
    "    plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
    "                                  100*np.max(predictions_array),\n",
    "                                  class_names[true_label]),\n",
    "                                  color=color)\n",
    "\n",
    "    \n",
    "def plot_value_array(i, predictions_array, true_label):\n",
    "    \"\"\"Plots the value arrays associated with particular predictions\"\"\"\n",
    "    predictions_array, true_label = predictions_array[i], true_label[i]\n",
    "    plt.grid(False)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    thisplot = plt.bar(range(len(class_names)), predictions_array, color=\"#777777\")\n",
    "    plt.ylim([0, 1])\n",
    "    predicted_label = np.argmax(predictions_array)\n",
    "\n",
    "    thisplot[predicted_label].set_color('#ee4433')\n",
    "    thisplot[true_label].set_color('#335599')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "    '''A Convolutional Classifier'''\n",
    "    \n",
    "    # define initialization\n",
    "    def __init__(self):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.norm1 = nn.BatchNorm2d(64)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 64, out_channels = 128, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.norm2 = nn.BatchNorm2d(128)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 128, out_channels = 256, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.norm3 = nn.BatchNorm2d(256)\n",
    "        self.conv4 = nn.Conv2d(in_channels = 256, out_channels = 512, kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.norm4 = nn.BatchNorm2d(512)\n",
    "        self.max_pool = nn.MaxPool2d(2, 2)\n",
    "        self.full_conn = nn.Linear(32768, 100)\n",
    "    # define network structure\n",
    "    def forward(self, x):\n",
    "        input_size = x.size(0)\n",
    "        x = F.relu(self.norm1(self.conv1(x)))\n",
    "        x = F.relu(self.max_pool(self.norm2(self.conv2(x))))\n",
    "        x = F.relu(self.norm3(self.conv3(x)))\n",
    "        x = F.relu(self.max_pool(self.norm4(self.conv4(x))))\n",
    "        x = x.view(input_size, -1)\n",
    "        x = self.full_conn(x)\n",
    "        return x\n",
    "\n",
    "class Checkpointer:\n",
    "    \"\"\"Object that sets checkpoints based on test accuracy. \n",
    "    A class is used to maintain a state\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"initializes instance variables\"\"\"\n",
    "        self.max_accuracy = 0\n",
    "        self.epoch = epoch\n",
    "        self.best_state_dict = None\n",
    "        \n",
    "    def __call__(self, model, epoch, curr_acc):\n",
    "        \"\"\" When the checkpointer is called on a current accuracy measure for a given model,\n",
    "            check whether the current accuracy is greater than at the last checkpoint, \n",
    "            if so record it.\n",
    "        \"\"\"\n",
    "        # if the max accuracy has yet to be measured (base case)\n",
    "        if self.max_accuracy == 0:\n",
    "            # set it to the one currently being checked for\n",
    "            self.max_accuracy = curr_acc\n",
    "            \n",
    "        # if the current accuracy is better than previously recorded\n",
    "        elif self.max_accuracy < curr_acc:\n",
    "            # update the best accuracy\n",
    "            self.max_accuracy = curr_acc\n",
    "            # record a checkpoint\n",
    "            self.checkpoint(model, epoch)\n",
    "    \n",
    "    def checkpoint(self, model, epoch):\n",
    "        \"\"\"Saves the model for it to be loaded later on. Takes note of the checkpoint epoch\"\"\"\n",
    "        print(f'Setting checkpoint')\n",
    "        self.best_state_dict = model.state_dict()\n",
    "        self.epoch = epoch\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define list containing class names\n",
    "class_names = ['apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle', 'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel', 'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock', 'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur', 'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster', 'house', 'kangaroo', 'computer_keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion', 'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle',\n",
    "               'mountain', 'mouse', 'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear', 'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine', 'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose', 'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake', 'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table', 'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout', 'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm', ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define train transform (can add augmentation)\n",
    "train_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])\n",
    "\n",
    "# define test transfrom (no augmentation should be added)\n",
    "test_transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Datasets\n",
    "The training and validation datasets will both originate from the CIFAR training set. This is because later on they will be split according to some ratio such that for example training is 4/5 of the training set and validation is 1/5 of the training set. This is to perform regularization (such as early stopping) in an isolated manner from the testing dataset, which is in fact loaded from the test set.\n",
    "\n",
    "The careful reader will notice that despite being loaded from the same set, training and validation datasets still differ as each will have their own transforms, allowing the former for example to be augmented. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the training dataset from training\n",
    "train_dataset = torchvision.datasets.CIFAR100(root='data', train = True, download = True, transform = train_transform)\n",
    "\n",
    "# get the testing dataset from testing\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='data', train = False, download = True, transform = test_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Datasets for usage\n",
    "We've downloaded the data. Now we have to load it for our model to use it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instantiate data objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 4\n",
    "\n",
    "# instantiate trainingdata loader\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "\n",
    "# instantiate test data loader with no shuffling\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "# create iterators for later use\n",
    "train_iterator = iter(cycle(train_loader))\n",
    "test_iterator = iter(cycle(test_loader))\n",
    "\n",
    "print(f'> Size of training dataset {len(train_loader.dataset)}')\n",
    "print(f'> Size of test dataset {len(test_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Viewing Some of Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create pyplot figure\n",
    "plt.figure(figsize=(10, 10))\n",
    "# make a 5 by 5 grid of images from test dataset\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    # get rid of tickmarks\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    # get rid of grid\n",
    "    plt.grid(False)\n",
    "    # show the image\n",
    "    plt.imshow(test_loader.dataset[i][0].permute(\n",
    "        0, 2, 1).contiguous().permute(2, 1, 0), cmap=plt.cm.binary)\n",
    "    # label\n",
    "    plt.xlabel(class_names[test_loader.dataset[i][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize model object\n",
    "N = MyNetwork().to(device)\n",
    "\n",
    "print(f'> Number of network parameters {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
    "\n",
    "# initialise the optimiser (stochastic gradient descent)\n",
    "optimiser = torch.optim.SGD(N.parameters(), lr=0.01, weight_decay = 0.0001)\n",
    "# set start epoch\n",
    "epoch = 0\n",
    "\n",
    "# if we want to visualize rather than record\n",
    "VIS_BOOL = False\n",
    "\n",
    "# if we are recording the results instead:\n",
    "if not VIS_BOOL:\n",
    "    # initialize test record lists\n",
    "    test_acc = []\n",
    "    test_loss = []\n",
    "else:\n",
    "    # initialize live loss plot object\n",
    "    liveplot = PlotLosses()\n",
    "    \n",
    "# initialize checkpointer object\n",
    "check_pointer = Checkpointer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training process\n",
    "time_elapsed = 0\n",
    "start_time = timeit.default_timer()\n",
    "while (epoch < 100 and time_elapsed < 3600): # training for 99 epochs or less than 1 hr\n",
    "    # arrays for epoch metrics\n",
    "    train_loss_arr = np.zeros(0)\n",
    "    train_acc_arr = np.zeros(0)\n",
    "    # same for testing\n",
    "    test_loss_arr = np.zeros(0)\n",
    "    test_acc_arr = np.zeros(0)\n",
    "\n",
    "    # set the model to training mode\n",
    "    N.train()\n",
    "    # iterate over the training dataset (batch by batch)\n",
    "    for (x, t) in train_loader:\n",
    "        # set the data and target tensors to the GPU\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        # initialize the gradient to zero\n",
    "        optimiser.zero_grad()\n",
    "        # calculate prediction by running input through Neural Network\n",
    "        p = N(x)\n",
    "        # argmax to utilize for accuracy calculation\n",
    "        pred = p.argmax(dim=1, keepdim=True)\n",
    "        # calculate loss between prediction and target\n",
    "        loss = torch.nn.functional.cross_entropy(p, t)\n",
    "        # backpropagate loss\n",
    "        loss.backward()\n",
    "        # performs a parameter update (train)\n",
    "        optimiser.step()  \n",
    "        # if we want to visualize our results\n",
    "        if VIS_BOOL:\n",
    "            # record the loss for this image\n",
    "            train_loss_arr = np.append(train_loss_arr, loss.cpu().data)\n",
    "            # record the accuracy for this image\n",
    "            train_acc_arr = np.append(train_acc_arr, pred.data.eq(\n",
    "                t.view_as(pred)).float().mean().item())\n",
    "    \n",
    "    # set the model to evaluation mode\n",
    "    N.eval()\n",
    "    # iterate over the test dataset (batch by batch)\n",
    "    for x, t in test_loader: \n",
    "        # get input and respective targets from testing dataset\n",
    "        x, t = x.to(device), t.to(device)\n",
    "        # calculate prediction by running input through Neural Network\n",
    "        p = N(x)\n",
    "        # calculate loss\n",
    "        loss = torch.nn.functional.cross_entropy(p, t)\n",
    "        # argmax to utilize for accuracy calculation\n",
    "        pred = p.argmax(dim=1, keepdim=True)\n",
    "        # record the loss for this image\n",
    "        test_loss_arr = np.append(test_loss_arr, loss.cpu().data)\n",
    "        # record the accuracy for this image\n",
    "        test_acc_arr = np.append(test_acc_arr, pred.data.eq(\n",
    "            t.view_as(pred)).float().mean().item())\n",
    "\n",
    "        \n",
    "    # if we want to visualize live\n",
    "    if VIS_BOOL:\n",
    "        # draw the training results live\n",
    "        # NOTE: live plot library has naming forcing our 'test' to be called 'validation'\n",
    "        liveplot.update({\n",
    "            'accuracy': train_acc_arr.mean(),\n",
    "            'val_accuracy': test_acc_arr.mean(),\n",
    "            'loss': train_loss_arr.mean(),\n",
    "            'val_loss': test_loss_arr.mean()\n",
    "        })\n",
    "        liveplot.draw()\n",
    "    \n",
    "    # if we prefer to record the results for later usage\n",
    "    else:\n",
    "        # record the test accuracy and loss for this epoch\n",
    "        test_acc.append(test_acc_arr.mean())\n",
    "        test_loss.append(test_loss_arr.mean())\n",
    "        # print to keep track of progress\n",
    "        print(epoch, time_elapsed)\n",
    "    \n",
    "    # record checkpoint if necessary\n",
    "    check_pointer(N, epoch, test_acc_arr.mean())\n",
    "    \n",
    "    # move on to the next epoch\n",
    "    epoch += 1\n",
    "    time_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "print (\"Training completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Post-Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving the model\n",
    "I save the model in case I want to come back to it. When using Google Colab, my Google Drive is mounted from previous steps so I save it to there. When running the script locally, I of course simply save the results locally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the epoch at which best accuracy was recorded\n",
    "best_epoch = check_pointer.epoch\n",
    "# getting the respective model dictionary at that epoch\n",
    "best_dict = check_pointer.best_state_dict\n",
    "\n",
    "# building the json file we want to serialize\n",
    "save_object = {\n",
    "    \"state_dict\" : best_dict,\n",
    "    \"best_epoch\" : best_epoch,\n",
    "    \"test_accuracy\": test_acc,\n",
    "    \"test_loss\": test_loss\n",
    "}\n",
    "\n",
    "# creating file name\n",
    "file_name = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# setting save path - uncomment one of these lines accordingly\n",
    "# SAVE_DIR = \"/content/gdrive/My Drive/Education/Undergraduate/Year_3/Computer_Science/SSA/Machine_Learning/Coursework/ML_Classifier-Pegasus-Generator/Training/Classifier/Models/{}.pickle\".format(file_name)\n",
    "SAVE_DIR = \"Training/Classifier/Models/{}.pickle\".format(file_name)\n",
    "\n",
    "# saving\n",
    "with open(SAVE_DIR, 'wb') as outfile:  \n",
    "    pickle.dump(save_object, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the model\n",
    "This portion of code allows me to load a different model if I wish, by uncommenting and editing the first line of code. Otherwise it will load the model we just saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment this and specify filename (without extension) if you wish to load different file\n",
    "# file_name = 'placeholder'\n",
    "\n",
    "# reforming the directory\n",
    "SAVE_DIR = '/'.join(SAVE_DIR.split('/')[:-1]) + '/{}.pickle'.format(file_name)\n",
    "\n",
    "# load JSON object\n",
    "with open(SAVE_DIR, 'rb') as handle:  \n",
    "    load_object = pickle.load(handle)\n",
    "\n",
    "# loading the object and parsing its contents\n",
    "# the state dictionary is loaded into the model\n",
    "N.load_state_dict(load_object[\"state_dict\"])\n",
    "# the best epoch is parsed\n",
    "best_epoch = load_object[\"best_epoch\"]\n",
    "# the test loss and accuracy lists are loaded\n",
    "test_acc = load_object[\"test_accuracy\"]\n",
    "test_loss = load_object[\"test_loss\"]\n",
    "# the epochs the model ran for are recalculated \n",
    "epoch = len(test_acc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = next(test_iterator)\n",
    "test_images, test_labels = test_images.to(device), test_labels.to(device)\n",
    "# perform inference on the test dataset - use softmax to format this as a sum of probabilities normalized to 1\n",
    "test_preds = torch.softmax(N(test_images).view(test_images.size(0), len(class_names)), dim=1).data.squeeze().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 4\n",
    "num_cols = 4\n",
    "num_images = num_rows*num_cols\n",
    "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
    "for i in range(num_images):\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
    "    plot_image(i, test_preds, test_labels.cpu(), test_images.cpu().squeeze().permute(1,3,2,0).contiguous().permute(3,2,1,0))\n",
    "    plt.subplot(num_rows, 2*num_cols, 2*i+2)\n",
    "    plot_value_array(i, test_preds, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Test Loss and Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting best accuracy\n",
    "best_accuracy = np.max(test_acc)\n",
    "\n",
    "# if we had previously decided to record the test accuracy and loss throughout\n",
    "if not VIS_BOOL:\n",
    "    # plot along all the training epochs\n",
    "    epochs_arr = list(range(0, epoch))\n",
    "    # initialize pyplot object\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "    # plot accuracy\n",
    "    ax1.plot(epochs_arr, test_acc)\n",
    "    # label best accuracy\n",
    "    ax1.hlines(best_accuracy, 0, best_epoch, linestyles = 'dashed', colors = 'red', linewidth = 1)\n",
    "    ax1.vlines(best_epoch, 0, best_accuracy, linestyles = 'dashed', colors = 'red', linewidth = 1)\n",
    "    ax1.set_xlabel(\"Epochs\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.set_title(\"Test Accuracy over Training Epochs\")\n",
    "    # plot loss\n",
    "    ax2.plot(epochs_arr, test_loss)\n",
    "    ax2.set_xlabel(\"Epochs\")\n",
    "    ax2.set_ylabel(\"Loss\")\n",
    "    ax2.set_title(\"Test Loss over Training Epochs\")\n",
    "    \n",
    "    fig.tight_layout()\n",
    "else:\n",
    "    print(\"You have not previously recorded the test accuracy and loss over time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Best Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not VIS_BOOL:\n",
    "    print(\"The best value for the test accuracy is {} %\".format(best_accuracy*100))\n",
    "else:\n",
    "    print(\"You have not previously recorded the test accuracy and loss over time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
