{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pegasus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google COLAB Settings\n",
    "In this section are certain processes that should be run when running the code through Google COLAB so to have access to a GPU. If such is the case, uncomment the sections and run them sequentially. otherwise, feel free to skip directly to [Imports](#Imports)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X0XeNJMELfIb"
   },
   "outputs": [],
   "source": [
    "# %%capture\n",
    "# from os.path import exists\n",
    "# from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
    "# platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
    "# cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
    "# accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
    "# !pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
    "# !pip install livelossplot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Drive\n",
    "This portion is exclusively for development on _my_ end. I use Google Drive to access the training/testing data without having to redownload it each time the Google COLAB runtime is reset. \n",
    "\n",
    "Of course anyone who does not have access to my Google credentials will not be able to access my Drive. As such, these users should skip directly to [Imports](#Imports). The result will be that torchvision will personally download the CIFAR data from the web each time the COLAB runtime is reset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mounting Drive\n",
    "This mounts Google Drive to the local runtime. If Drive is already mounted, then of course, it will not try to mount it again. It will of course ask for authentication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing data from Drive\n",
    "Here I import the CIFAR data which I have previously downloaded and stored in my Google Drive. To do so I copy the corresponding directory from my Google Drive into the COLAB Runtime to avoid having to redownload it each time my COLAB runtime is reset. The ```-n``` flag is set to avoid overwriting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cp -r -n /content/gdrive/My\\ Drive/Education/Undergraduate/Year_3/Computer_Science/SSA/Machine_Learning/Coursework/ML_Classifier-Pegasus-Generator/data/ /content/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6N22Uz-kLiZW"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MK1Jl7nkLnPA"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cycle(iterable):\n",
    "    \"\"\"helper function to make getting another batch of data easier\"\"\"\n",
    "    while True:\n",
    "        for x in iterable:\n",
    "            yield x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qnjh12UbNFpV"
   },
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "RGbLY6X-NH4O",
    "outputId": "018313f3-afa4-43ad-c72d-1f51fe5aedb6"
   },
   "outputs": [],
   "source": [
    "class MyNetwork(nn.Module):\n",
    "    \"\"\"define the model (a simple autoencoder)\"\"\"\n",
    "    def __init__(self):\n",
    "        super(MyNetwork, self).__init__()\n",
    "        layers = nn.ModuleList()\n",
    "        layers.append(nn.Linear(in_features=3*32*32, out_features=512))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(in_features=512, out_features=32))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(in_features=32, out_features=512))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(in_features=512, out_features=3*32*32))\n",
    "        layers.append(nn.Sigmoid())\n",
    "        self.layers = layers\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.encode(x)\n",
    "        x = self.decode(z)\n",
    "        return x\n",
    "\n",
    "    def encode(self, x):\n",
    "        \"\"\"encode (flatten as linear, then run first half of network)\"\"\"\n",
    "        x = x.view(x.size(0), -1)\n",
    "        for i in range(4):\n",
    "            x = self.layers[i](x)\n",
    "        return x\n",
    "\n",
    "    def decode(self, x):\n",
    "        \"\"\"decode (run second half of network then unflatten)\"\"\"\n",
    "        for i in range(4,8):\n",
    "            x = self.layers[i](x)\n",
    "        x = x.view(x.size(0), 3, 32, 32)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "run1dh_hM0oO"
   },
   "source": [
    "## Dataset Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 86
    },
    "colab_type": "code",
    "id": "bK383zeDM4Ac",
    "outputId": "5a7bb37e-9b16-4f87-9c7e-6b07c5ed8d2e"
   },
   "outputs": [],
   "source": [
    "# define class names for CIFAR 10\n",
    "class_names = ['airplane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms to be applied to training data\n",
    "train_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "# define transforms to be applied to testing data\n",
    "test_transforms = torchvision.transforms.Compose([\n",
    "        torchvision.transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Data\n",
    "If not already present, this cell will download the [CIFAR 10](https://www.cs.toronto.edu/~kriz/cifar.html) dataset from the web. Otherwise it will simply read it from the existing directory. The transforms defined [above](#Transforms) will be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download training set\n",
    "train_set = torchvision.datasets.CIFAR10('data', train=True, download=True, transform=train_transforms)\n",
    "# download test set\n",
    "test_set = torchvision.datasets.CIFAR10('data', train=False, download=True, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Data\n",
    "Having obtained the data, it needs to be loaded into an iterable format for pytorch to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define batch size\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# load training set into a data torch data object, shuffled\n",
    "train_loader = torch.utils.data.DataLoader(train_set, shuffle=True, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "# load test set into a data torch data object, unshuffled\n",
    "test_loader = torch.utils.data.DataLoader(test_set, shuffle=False, batch_size=BATCH_SIZE, drop_last=True)\n",
    "\n",
    "# create iterators for later use\n",
    "train_iterator = iter(cycle(train_loader))\n",
    "test_iterator = iter(cycle(test_loader))\n",
    "\n",
    "# diagnostic prints\n",
    "print(f'> Size of training dataset {len(train_loader.dataset)}')\n",
    "print(f'> Size of test dataset {len(test_loader.dataset)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q-FdW5HnimG2"
   },
   "source": [
    "### Viewing (some of) the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "colab_type": "code",
    "id": "BtJs-qxHRLXz",
    "outputId": "c504705d-1713-4251-8698-6a260807f0a9"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(25):\n",
    "    plt.subplot(5,5,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(test_loader.dataset[i][0].permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[test_loader.dataset[i][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiliaze the network instance\n",
    "N = MyNetwork().to(device)\n",
    "\n",
    "print(f'> Number of network parameters {len(torch.nn.utils.parameters_to_vector(N.parameters()))}')\n",
    "\n",
    "# initialise the optimiser\n",
    "optimiser = torch.optim.Adam(N.parameters(), lr=0.001)\n",
    "# initialize the epochs\n",
    "epoch = 0\n",
    "# initialize livelossplot instance\n",
    "liveplot = PlotLosses()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1UBl0PJjY-f"
   },
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "id": "kb5909Y8D_zx",
    "outputId": "f24a34b5-d39d-420b-cfd6-e0572b9d2fa5"
   },
   "outputs": [],
   "source": [
    "# training loop, feel free to also train on the test dataset if you like for generating the pegasus\n",
    "while (epoch<10):\n",
    "    \n",
    "    # arrays for metrics\n",
    "    train_loss_arr = np.zeros(0)\n",
    "\n",
    "    # iterate over some of the train dateset\n",
    "    for i in range(1000):\n",
    "        # get data and respective target batch samples\n",
    "        x,t = next(train_iterator)\n",
    "        # place them onto the GPU\n",
    "        x,t = x.to(device), t.to(device)\n",
    "        \n",
    "        # set the gradient to zero\n",
    "        optimiser.zero_grad()\n",
    "        # calculate a prediction\n",
    "        p = N(x)\n",
    "        # calculate the loss\n",
    "        loss = ((p-x)**2).mean() # simple l2 loss\n",
    "        # backpropagate the loss \n",
    "        loss.backward()\n",
    "        # train\n",
    "        optimiser.step()\n",
    "        # record the losses for each data/target pair\n",
    "        train_loss_arr = np.append(train_loss_arr, loss.cpu().data)\n",
    "\n",
    "    # plot the training loss\n",
    "    liveplot.update({\n",
    "        'loss': train_loss_arr.mean()\n",
    "    })\n",
    "    liveplot.draw()\n",
    "    \n",
    "    # move on to the next epoch\n",
    "    epoch = epoch+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MTFqiEHzMOVw"
   },
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 364
    },
    "colab_type": "code",
    "id": "nqv3w6b0nKbr",
    "outputId": "b7943d50-41cc-4710-8be8-eae3585fdbcf"
   },
   "outputs": [],
   "source": [
    "# get the Tensors for a horse and for a bird\n",
    "example_1 = (test_loader.dataset[13][0]).to(device)  # horse\n",
    "example_2 = (test_loader.dataset[160][0]).to(device) # bird\n",
    "\n",
    "# run them through the encoder\n",
    "example_1_code = N.encode(example_1.unsqueeze(0))\n",
    "example_2_code = N.encode(example_2.unsqueeze(0))\n",
    "\n",
    "# decode an interpolation of the two\n",
    "bad_pegasus = N.decode(0.9*example_1_code + 0.1*example_2_code).squeeze(0)\n",
    "\n",
    "# plot the result of the decoding\n",
    "plt.grid(False)\n",
    "plt.imshow(bad_pegasus.cpu().data.permute(0,2,1).contiguous().permute(2,1,0), cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oek8E0uRC7aQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "coursework-pegasus.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
